{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pemodelan Klasifikasi Regresi Logistik Multinomial "
      ],
      "metadata": {
        "id": "pU12xSL5chj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "poeWBqZDcnbU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTwpVu8m4G7q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "v1-cqy4ecpn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/label_data_prabowo.csv')\n",
        "data.dropna(subset=['cleaned'], inplace=True)\n",
        "print(data.shape)\n",
        "print(data.head())\n",
        "print(data.duplicated().any()) \n",
        "print(data.isnull().any() )\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuDuaOeK4Pc9",
        "outputId": "7817a6ce-94c3-47fd-cef2-8a2239f85873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4040, 8)\n",
            "         date                                                url  \\\n",
            "0  2022-11-30  https://twitter.com/Mewmewtho/status/159806777...   \n",
            "1  2022-11-30  https://twitter.com/fadhlierlanda/status/15979...   \n",
            "2  2022-11-30  https://twitter.com/ZimanPargaD/status/1597960...   \n",
            "3  2022-11-30  https://twitter.com/chandrajuni82/status/15979...   \n",
            "4  2022-11-30  https://twitter.com/Gardabangsaa/status/159792...   \n",
            "\n",
            "        username                                            content  \\\n",
            "0      Mewmewtho  @azwarsiregar @solehuddin_plg @prabowo Kadrun ...   \n",
            "1  fadhlierlanda  @PrayudhaRangga @azwarsiregar @prabowo Saya ma...   \n",
            "2    ZimanPargaD  @Irwan2yah @DivHumas_Polri @Puspen_TNI @tni_ad...   \n",
            "3  chandrajuni82  Survey pernah memenangkan @prabowo yang jadi p...   \n",
            "4   Gardabangsaa  Lembaga survei Median merilis hasil simulasi h...   \n",
            "\n",
            "                                             cleaned  \\\n",
            "0     kadrun sejati pilih ideologi kuat pikir sempat   \n",
            "1  kampanye tunjuk kemampuanya komunikasi kalang ...   \n",
            "2  betul sibuk benah negeri mafia tentara nasiona...   \n",
            "3  survey menang hasil menang lembaga survey lucu...   \n",
            "4  lembaga survei median rilis hasil simulasi hea...   \n",
            "\n",
            "                                          cleaned_en  polarity    label  \n",
            "0    true kadrun choose a strong ideology think once  0.391667  Positif  \n",
            "1  The campaign demonstrates its ability to commu...  0.500000  Positif  \n",
            "2  really busy fixing the mafia country, the nati...  0.100000  Positif  \n",
            "3  survey wins winning results stupid funny surve...  0.062500  Positif  \n",
            "4  The median survey agency released the results ... -0.500000  Negatif  \n",
            "False\n",
            "date          False\n",
            "url           False\n",
            "username      False\n",
            "content       False\n",
            "cleaned       False\n",
            "cleaned_en    False\n",
            "polarity      False\n",
            "label         False\n",
            "dtype: bool\n",
            "(4040, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data"
      ],
      "metadata": {
        "id": "DxMLOV9hcrFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2022\n",
        "X = data\n",
        "y = data['label']"
      ],
      "metadata": {
        "id": "DD_GFomB4T5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)"
      ],
      "metadata": {
        "id": "1Z0kfXlE4VWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "y_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "by9KxejG4WR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = X_test\n",
        "X_test = X_test['cleaned']\n",
        "X_train = X_train['cleaned']"
      ],
      "metadata": {
        "id": "3-aF-xMO4XFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting model"
      ],
      "metadata": {
        "id": "ZW9GPOefcuTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "vectorizer = TfidfVectorizer(lowercase=True)"
      ],
      "metadata": {
        "id": "zxY9QsWk4ZPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe= Pipeline([('vectorizer',vectorizer),('classifier',model)])"
      ],
      "metadata": {
        "id": "SeCSBApS4aw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
        "fold_num = 1\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    X_train_fold, X_test_fold = X_train.loc[train_index], X_train.loc[test_index]\n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "    pipe.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = pipe.predict(X_test_fold)\n",
        "    score = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
        "    scores.append(score)\n",
        "    print('Fold: %2d, F1-score: %.3f' % (fold_num, score*100))\n",
        "    fold_num += 1\n",
        "\n",
        "print('\\n\\nCross-Validation f1-score: %.3f +/- %.3f' %(np.mean(scores)*100, np.std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJSmXi2t4cc8",
        "outputId": "acc17bc9-2ea5-4ee9-be84-950499fcbdc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold:  1, F1-score: 79.237\n",
            "Fold:  2, F1-score: 80.198\n",
            "Fold:  3, F1-score: 77.106\n",
            "Fold:  4, F1-score: 81.112\n",
            "Fold:  5, F1-score: 75.511\n",
            "Fold:  6, F1-score: 80.255\n",
            "Fold:  7, F1-score: 82.347\n",
            "Fold:  8, F1-score: 78.904\n",
            "Fold:  9, F1-score: 83.344\n",
            "Fold: 10, F1-score: 77.887\n",
            "\n",
            "\n",
            "Cross-Validation f1-score: 79.590 +/- 0.023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pendugaan parameter"
      ],
      "metadata": {
        "id": "QX2m7X8LcxQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = pipe.named_steps['vectorizer'].get_feature_names()\n",
        "pendugaan_parameter = pd.DataFrame(feature_names, columns=['features'])\n",
        "\n",
        "pendugaan_parameter['g1'] = pipe.named_steps['classifier'].coef_[0]\n",
        "pendugaan_parameter['g2'] = pipe.named_steps['classifier'].coef_[2]\n",
        "pendugaan_parameter = pd.DataFrame([['Intersep', pipe.named_steps['classifier'].intercept_[0], pipe.named_steps['classifier'].intercept_[2]]], columns=pendugaan_parameter.columns).append(pendugaan_parameter)\n",
        "pendugaan_parameter.to_csv('pendugaan_parameter_prabowo.csv', encoding='utf8', index=False)\n",
        "pendugaan_parameter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "nEVMLbH94tHl",
        "outputId": "39d086f9-e58d-48f6-c7d8-17a0b3726ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      features        g1        g2\n",
              "0     Intersep -0.779633  0.153493\n",
              "0         abad -0.104413 -0.233307\n",
              "1        abadi  0.054352 -0.642401\n",
              "2         abah -0.034067 -0.085530\n",
              "3         abal -0.081886  0.229041\n",
              "...        ...       ...       ...\n",
              "3233     zayed -0.192744  0.288356\n",
              "3234      zina  0.221358 -0.097554\n",
              "3235       zon  0.141197 -0.075784\n",
              "3236      zona  0.254336 -0.044215\n",
              "3237       zul -0.036600  0.138150\n",
              "\n",
              "[3239 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d6c3dd0-e665-4b1f-9b2f-49a559e7f7a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intersep</td>\n",
              "      <td>-0.779633</td>\n",
              "      <td>0.153493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abad</td>\n",
              "      <td>-0.104413</td>\n",
              "      <td>-0.233307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abadi</td>\n",
              "      <td>0.054352</td>\n",
              "      <td>-0.642401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abah</td>\n",
              "      <td>-0.034067</td>\n",
              "      <td>-0.085530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abal</td>\n",
              "      <td>-0.081886</td>\n",
              "      <td>0.229041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3233</th>\n",
              "      <td>zayed</td>\n",
              "      <td>-0.192744</td>\n",
              "      <td>0.288356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3234</th>\n",
              "      <td>zina</td>\n",
              "      <td>0.221358</td>\n",
              "      <td>-0.097554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3235</th>\n",
              "      <td>zon</td>\n",
              "      <td>0.141197</td>\n",
              "      <td>-0.075784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3236</th>\n",
              "      <td>zona</td>\n",
              "      <td>0.254336</td>\n",
              "      <td>-0.044215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3237</th>\n",
              "      <td>zul</td>\n",
              "      <td>-0.036600</td>\n",
              "      <td>0.138150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3239 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d6c3dd0-e665-4b1f-9b2f-49a559e7f7a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d6c3dd0-e665-4b1f-9b2f-49a559e7f7a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d6c3dd0-e665-4b1f-9b2f-49a559e7f7a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediksi data uji"
      ],
      "metadata": {
        "id": "9BP7kE8Jc0Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "final_score = f1_score(y_test, y_pred, average='weighted')*100\n",
        "final_score.round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYmdr5bQ4mqd",
        "outputId": "f17f58ca-b866-4f73-d1f0-20d501c17bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.049"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "Tqc01XkKc3sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"y_head\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "jX5TocyF4yFl",
        "outputId": "00c64bae-f4b6-43c2-a3e7-910257374de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menyimpan file model"
      ],
      "metadata": {
        "id": "YineKcIOc6bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "filename = 'prabowo_model.sav'\n",
        "joblib.dump(pipe, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QTw2v1c46U1",
        "outputId": "909fd967-bbd6-4a7f-89f3-7f498f8750ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prabowo_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediksi data input"
      ],
      "metadata": {
        "id": "HuYckICm49Ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load library"
      ],
      "metadata": {
        "id": "UTF9JHN0dBDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Detecting environment: \", end=' ')\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running the code in Google Colab. Installing and downloading dependencies.\\nPlease wait...\")\n",
        "    import nltk\n",
        "    !wget https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/lib/taudataNlpTm.py\n",
        "    !mkdir data\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/corpus_sederhana.txt\n",
        "    !pip install unidecode textblob sastrawi\n",
        "    nltk.download('popular')\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running the code locally.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC_9jO1548q-",
        "outputId": "16bf082e-b681-4780-efca-0c38e05154dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting environment:  Running the code in Google Colab. Installing and downloading dependencies.\n",
            "Please wait...\n",
            "--2023-01-24 22:34:10--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/lib/taudataNlpTm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5686 (5.6K) [text/plain]\n",
            "Saving to: ‘taudataNlpTm.py’\n",
            "\n",
            "taudataNlpTm.py     100%[===================>]   5.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-24 22:34:10 (67.6 MB/s) - ‘taudataNlpTm.py’ saved [5686/5686]\n",
            "\n",
            "--2023-01-24 22:34:11--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29041 (28K) [text/plain]\n",
            "Saving to: ‘data/slang.txt’\n",
            "\n",
            "slang.txt           100%[===================>]  28.36K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-01-24 22:34:11 (8.51 MB/s) - ‘data/slang.txt’ saved [29041/29041]\n",
            "\n",
            "--2023-01-24 22:34:11--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6446 (6.3K) [text/plain]\n",
            "Saving to: ‘data/stopwords_id.txt’\n",
            "\n",
            "stopwords_id.txt    100%[===================>]   6.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-24 22:34:11 (56.0 MB/s) - ‘data/stopwords_id.txt’ saved [6446/6446]\n",
            "\n",
            "--2023-01-24 22:34:11--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15140 (15K) [text/plain]\n",
            "Saving to: ‘data/stopwords_en.txt’\n",
            "\n",
            "stopwords_en.txt    100%[===================>]  14.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-24 22:34:11 (30.8 MB/s) - ‘data/stopwords_en.txt’ saved [15140/15140]\n",
            "\n",
            "--2023-01-24 22:34:11--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/corpus_sederhana.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 316963 (310K) [text/plain]\n",
            "Saving to: ‘data/corpus_sederhana.txt’\n",
            "\n",
            "corpus_sederhana.tx 100%[===================>] 309.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-01-24 22:34:11 (7.80 MB/s) - ‘data/corpus_sederhana.txt’ saved [316963/316963]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (0.15.3)\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Installing collected packages: sastrawi, unidecode\n",
            "Successfully installed sastrawi-1.0.1 unidecode-1.3.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "from html import unescape\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXX97o5q5AlV",
        "outputId": "43314223-40e3-45ad-ce88-7b9f429ea1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load stopwords"
      ],
      "metadata": {
        "id": "n0NEHTpSdEAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Stopwords: Ada beberapa cara\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "\n",
        "NLTK_StopWords = stopwords.words('indonesian')\n",
        "Sastrawi_StopWords_id = factory.get_stop_words()\n",
        "\n",
        "df=open('data/stopwords_id.txt',\"r\",encoding=\"utf-8\", errors='replace')\n",
        "id_stop = df.readlines()\n",
        "df.close()\n",
        "id_stop = [t.strip().lower() for t in id_stop]\n",
        "\n",
        "with open('more_stopwords.txt', 'r') as f:\n",
        "    kamus = f.readline().split(',')\n",
        "    more_stopwords = []\n",
        "    for x in kamus:\n",
        "        text = re.sub('[\\s]+', '', x)\n",
        "        more_stopwords.append(text)\n",
        "\n",
        "with open('exclude_stopwords.txt', 'r') as f:\n",
        "    kamus = f.readline().split(',')\n",
        "    exclude_stopwords = []\n",
        "    for x in kamus:\n",
        "        text = re.sub('[\\s]+', '', x)\n",
        "        exclude_stopwords.append(text)\n",
        "\n",
        "N = 10\n",
        "print(NLTK_StopWords[:N])\n",
        "print(Sastrawi_StopWords_id[:N])\n",
        "print(id_stop[:N])\n",
        "#print(more_stopwords[:N])\n",
        "print(len(Sastrawi_StopWords_id), len(id_stop), len(NLTK_StopWords), len(more_stopwords))\n",
        "print(type(Sastrawi_StopWords_id), type(id_stop), type(NLTK_StopWords), type(more_stopwords))\n",
        "\n",
        "#Stopword\n",
        "stops = set(Sastrawi_StopWords_id + id_stop + NLTK_StopWords + more_stopwords)\n",
        "#exclude = [\"tidak\", 'benar', 'betul', 'baik', 'belum', 'boleh', 'dekat', 'guna', 'mampu', 'masalah', 'nggak', 'pasti', 'penting', 'percuma', 'rasa', 'satu', 'tegas', 'tunjuk', 'yakin', 'usah']\n",
        "exclude = exclude_stopwords\n",
        "for i in exclude:\n",
        "  stops.discard(i)\n",
        "print(len(stops))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YxrpPEB5FfV",
        "outputId": "39388095-5584-47e8-8ef6-9fc4fc56909c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir']\n",
            "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua']\n",
            "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir']\n",
            "126 758 758 1353\n",
            "<class 'list'> <class 'list'> <class 'list'> <class 'list'>\n",
            "1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load slang words"
      ],
      "metadata": {
        "id": "j13ykXSMdGGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sumber github\n",
        "indo_slang_words = pd.read_csv(\"https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv\")\n",
        "indo_slang_words = indo_slang_words.iloc[:,:2]\n",
        "print('jumlah slang words: ', len(indo_slang_words))\n",
        "# sumber tau data\n",
        "df=open('data/slang.txt',\"r\",encoding=\"utf-8\", errors='replace')\n",
        "slangS = df.readlines(); df.close()\n",
        "slangS = [t.strip('\\n').strip() for t in slangS] # remove enter\n",
        "slangS = [t.split(\":\") for t in slangS] # split based on ':'\n",
        "slangS = [[k.strip(), v.strip()] for k,v in slangS] # remove white space\n",
        "slangS = np.array(slangS) # convert to numpy\n",
        "slang = slangS[:,0]\n",
        "formal = slangS[:,1]\n",
        "more_slang_words = pd.DataFrame(slangS[:,0], columns=['slang'])\n",
        "more_slang_words['formal'] = formal\n",
        "print('jumlah slang words: ', len(more_slang_words))\n",
        "# combine slang words\n",
        "all_slang_words = pd.concat([indo_slang_words, more_slang_words])\n",
        "all_slang_words.drop_duplicates(subset='slang', keep='first', inplace=True)\n",
        "print('jumlah slang words: ', len(all_slang_words))\n",
        "slang_words = all_slang_words.set_index('slang').T.to_dict(orient='records')\n",
        "dict_slang_words = slang_words[0]\n",
        "print('kata normal dari kata 7an yaitu: ', dict_slang_words['7an'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU8AbSEc5GjV",
        "outputId": "526b3281-a9f7-4ebb-cef1-0d2feb65c062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumlah slang words:  15006\n",
            "jumlah slang words:  1692\n",
            "jumlah slang words:  5515\n",
            "kata normal dari kata 7an yaitu:  tujuan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fungsi text preprocessing"
      ],
      "metadata": {
        "id": "Bvr6_1xzdJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Emoji\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "def hashtags(text):\n",
        "  \"\"\"Menyimpan hashtags\"\"\"\n",
        "  getHashtags = re.compile(r\"#(\\w+)\")\n",
        "  pisahtags = re.compile(r'[\\w][^A-Z]*')\n",
        "  tagS = re.findall(getHashtags, text)\n",
        "  for tag in tagS:\n",
        "      proper_words = ' '.join(re.findall(pisahtags, tag))\n",
        "      text = text.replace('#'+tag,proper_words)\n",
        "  return text\n",
        "\n",
        "def removeConsecutiveDuplicates(text):\n",
        "    if len(text) < 2:\n",
        "        return text\n",
        "    if text[0] != text[1]:\n",
        "        return text[0]+removeConsecutiveDuplicates(text[1:])\n",
        "    return removeConsecutiveDuplicates(text[1:])\n",
        "\n",
        "def normalization(text):\n",
        "  T = TextBlob(text).words\n",
        "  for i,t in enumerate(T):\n",
        "      if t in dict_slang_words.keys():\n",
        "          T[i] = dict_slang_words[t]\n",
        "  return ' '.join(T)\n",
        "\n",
        "def datePreproc(date):\n",
        "    date = re.sub('(T[\\w:+]*)', '', str(date))\n",
        "    return date\n",
        "\n",
        "urlPattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "\n",
        "def caseFolding(text):\n",
        "    #Convert to lower case\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def cleansing1(text):\n",
        "    #Get hashtags\n",
        "    #text = hashtags(text)\n",
        "    #Remove hashtags\n",
        "    text = re.sub('#(\\w+)', ' ', text)\n",
        "    #Remove enter\n",
        "    text = re.sub('(\\n)', ' ', text)\n",
        "    #Representasi ASCII terdekat\n",
        "    text = unidecode(text)\n",
        "    #Clean html entity\n",
        "    text = unescape(text)\n",
        "    #Remove emoji\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    #Remove email\n",
        "    text = re.sub('[\\w._%+-]+@[\\w\\.-]+\\.[a-zA-Z]{2,4}', ' ', text)\n",
        "    #Remove @username\n",
        "    text = re.sub('@[\\w]*', ' ', text)\n",
        "    #Remove Website URLS\n",
        "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)\n",
        "    #Remove additional white spaces\n",
        "    text = re.sub('[\\s]+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def cleansing2(text):\n",
        "    #Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]|_', ' ', text)\n",
        "    #Remove number\n",
        "    text = re.sub('[\\d]+', ' ', text)\n",
        "    #Remove double character\n",
        "    text = removeConsecutiveDuplicates(text) #https://www.geeksforgeeks.org/remove-consecutive-duplicates-string/\n",
        "    #Remove additional white spaces\n",
        "    text = re.sub('[\\s]+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def stopwordRemover(word_tokens):\n",
        "    '''input berupa kalimat yang sudah ditoken (from nltk.tokenize import word_tokenize)'''\n",
        "    word_no_stopwords = [w for w in word_tokens if not w in stops]\n",
        "    word_no_stopwords = \" \".join(word_no_stopwords)\n",
        "    return word_no_stopwords\n",
        "\n",
        "def preprocess(text):\n",
        "    stemmer = StemmerFactory().create_stemmer()\n",
        "    text = str(text)\n",
        "    text = cleansing1(text) \n",
        "    lower_text = caseFolding(text) \n",
        "    formal_text = normalization(lower_text) \n",
        "    clean_text = cleansing2(formal_text) \n",
        "    words = word_tokenize(clean_text) \n",
        "    text = stopwordRemover(words)\n",
        "    text = stemmer.stem(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "GwxaeXLz5HW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "WTeJbQuJdMir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = joblib.load('/content/prabowo_model.sav')\n",
        "vectorizer = TfidfVectorizer(lowercase=True)\n",
        "pipe= Pipeline([('vectorizer', vectorizer),\n",
        "                ('classifier', loaded_model)])"
      ],
      "metadata": {
        "id": "bFSHi8Nk5ME2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melakukan prediksi"
      ],
      "metadata": {
        "id": "f7CVHYpIdO8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coba prediksi sentimen suatu kalimat.\")\n",
        "run = 'y'\n",
        "while run == 'y':\n",
        "    text = input(\"Masukkan kalimat yang akan dilakukan prediksi sentimen: \")\n",
        "    text = preprocess(text)\n",
        "    X_test = []\n",
        "    X_test.append(text)\n",
        "    preds = loaded_model.predict(X_test)\n",
        "    print(\"Kalimat tersebut memiliki sentimen: {}\".format(preds[0]))\n",
        "    run = input(\"Apakah ingin mencoba kembali? (y/n): \")\n",
        "print(\"Terima kasih dan sampai jumpa.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22cQGBfF5Pcd",
        "outputId": "39c278ee-952d-408c-cb97-c706f337cc42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coba prediksi sentimen suatu kalimat.\n",
            "Masukkan kalimat yang akan dilakukan prediksi sentimen: @prabowo keren sukses\n",
            "Kalimat tersebut memiliki sentimen: Positif\n",
            "Apakah ingin mencoba kembali? (y/n): y\n",
            "Masukkan kalimat yang akan dilakukan prediksi sentimen: @prabowo calon abadi\n",
            "Kalimat tersebut memiliki sentimen: Netral\n",
            "Apakah ingin mencoba kembali? (y/n): y\n",
            "Masukkan kalimat yang akan dilakukan prediksi sentimen: @prabowo biarin jadi calon abadi\n",
            "Kalimat tersebut memiliki sentimen: Netral\n",
            "Apakah ingin mencoba kembali? (y/n): y\n",
            "Masukkan kalimat yang akan dilakukan prediksi sentimen: @prabowo bersinergi\n",
            "Kalimat tersebut memiliki sentimen: Netral\n",
            "Apakah ingin mencoba kembali? (y/n): n\n",
            "Terima kasih dan sampai jumpa.\n"
          ]
        }
      ]
    }
  ]
}